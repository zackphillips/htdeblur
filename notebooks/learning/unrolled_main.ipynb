{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unrolled Network using Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-12T00:16:56.292907Z",
     "start_time": "2018-11-12T00:16:56.241648Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Decorators\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib notebook\n",
    "\n",
    "use_cuda = False\n",
    "#General\n",
    "import torch\n",
    "import os, glob\n",
    "\n",
    "if use_cuda:\n",
    "    torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
    "import torchvision\n",
    "import numpy as np\n",
    "\n",
    "#Used for data\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "#Used to define densenet\n",
    "import torch.nn as nn\n",
    "from torchvision import models\n",
    "from torchvision.models.densenet import DenseNet\n",
    "from torchvision.models.densenet import OrderedDict\n",
    "from torchvision.models.densenet import _DenseBlock\n",
    "from torchvision.models.densenet import _DenseLayer\n",
    "from torchvision.models.densenet import _Transition\n",
    "import torch.nn.functional as F\n",
    "\n",
    "#Used for optimization\n",
    "import torch.optim as optim\n",
    "\n",
    "#timing\n",
    "import contexttimer\n",
    "\n",
    "# Data directory\n",
    "data_dir = '/Users/zfphil/datasets/motiondeblur/learning_data/'\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-12T00:31:39.456716Z",
     "start_time": "2018-11-12T00:31:15.192146Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/zfphil/develop/libwallerlab/libwallerlab/projects/motiondeblur/notebooks_learning/data/learning_data/\n",
      "Loaded file 0\n",
      "Loaded file 100\n",
      "Loaded file 200\n",
      "Loaded file 300\n",
      "Loaded file 400\n",
      "Loaded file 500\n",
      "Loaded file 600\n",
      "Loaded file 700\n",
      "Loaded file 800\n",
      "Loaded file 900\n",
      "Loaded file 1000\n",
      "Loaded file 1100\n",
      "Loaded file 1200\n",
      "Loaded file 1300\n",
      "Loaded file 1400\n",
      "Loaded file 1500\n",
      "Loaded file 1600\n",
      "Loaded file 1700\n",
      "Loaded file 1800\n",
      "Loaded file 1900\n",
      "Loaded file 2000\n",
      "Loaded file 2100\n",
      "Loaded file 2200\n",
      "Loaded file 2300\n",
      "Loaded file 2400\n",
      "Loaded file 2500\n",
      "Loaded file 2600\n",
      "Loaded file 2700\n",
      "Loaded file 2800\n",
      "Loaded file 2900\n",
      "Loaded file 3000\n",
      "Loaded file 3100\n",
      "Loaded file 3200\n",
      "Loaded file 3300\n",
      "Loaded file 3400\n",
      "Loaded file 3500\n",
      "Loaded file 3600\n",
      "Loaded file 3700\n",
      "Loaded file 3800\n",
      "Loaded file 3900\n",
      "Loaded file 4000\n",
      "Loaded file 4100\n",
      "Loaded file 4200\n",
      "Loaded file 4300\n",
      "Loaded file 4400\n",
      "Loaded file 4500\n",
      "Loaded file 4600\n",
      "Loaded file 4700\n",
      "Loaded file 4800\n",
      "Loaded file 4900\n",
      "Loaded file 5000\n",
      "Loaded file 5100\n",
      "Loaded file 5200\n",
      "Loaded file 5300\n",
      "Loaded file 5400\n",
      "Loaded file 5500\n",
      "Loaded file 5600\n",
      "Loaded file 5700\n",
      "Loaded file 5800\n",
      "Loaded file 5900\n",
      "Loaded file 6000\n"
     ]
    }
   ],
   "source": [
    "class FresnelDataset(Dataset):\n",
    "    def __init__(self, data, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        self.transform = transform\n",
    "        self.data = data\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]\n",
    "    \n",
    "# Define output directory\n",
    "output_directory = \"%s/%s\"   % (os.getcwd(), \"data/learning_data/\")\n",
    "print(output_directory)\n",
    "# Find frames\n",
    "files = list(glob.glob(data_dir + '*.npz'))\n",
    "assert len(files) > 0\n",
    "files.sort()\n",
    "data_full = []\n",
    "for frame_index in range(len(files)):    \n",
    "    # Load data point (second line deals with weird structuring of .npz files)\n",
    "    _data = dict(np.load(files[frame_index]))\n",
    "    data = {key:_data[key].item() for key in _data}['arr_0']\n",
    "\n",
    "    input_data = np.real(data['measurements'][0]['array']).astype('float32')\n",
    "    output_data = np.real(data['ground_truth']['array']).astype('float32')\n",
    "    data_pair = (input_data[np.newaxis,0:128,0:128], output_data[np.newaxis,0:128,0:88])\n",
    "    data_full.append(data_pair)\n",
    "    if frame_index % 100 == 0:\n",
    "        print('Loaded file %d' % (frame_index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-12T00:32:21.613243Z",
     "start_time": "2018-11-12T00:32:21.557840Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class FresnelNet(nn.Module):\n",
    "    def __init__(self, growth_rate=32, block_config=(6, 12, 24, 16),\n",
    "                 num_init_features=64, bn_size=4, drop_rate=0, num_classes=1000, num_channels = 3, crop_size = (0,0)):\n",
    "        super(FresnelNet, self).__init__()\n",
    "        # Define structures\n",
    "        self.down_features = []\n",
    "        self.up_features = []        \n",
    "        \n",
    "        num_features = num_init_features\n",
    "        #First convolution (convolves to features)\n",
    "        self.first_layer = nn.Sequential(OrderedDict([\n",
    "            ('conv0', nn.Conv2d(num_channels, num_features, kernel_size=7, stride=1, padding=3, bias=False)),\n",
    "            ('norm0', nn.BatchNorm2d(num_features)),\n",
    "            ('relu0', nn.ReLU(inplace=True)),\n",
    "            ('conv1', nn.Conv2d(num_features, num_features, kernel_size=3, stride=1, padding=1, bias=False)),\n",
    "            ('norm1', nn.BatchNorm2d(num_features)),\n",
    "            ('relu1', nn.ReLU(inplace=True)),            \n",
    "        ]))\n",
    "        # Convolve again to reduce size\n",
    "        self.second_layer = nn.Sequential(OrderedDict([\n",
    "            ('conv0', nn.Conv2d(num_features, num_features, kernel_size=3, stride=2, padding=1, bias=False)),\n",
    "            ('norm0', nn.BatchNorm2d(num_features)),\n",
    "            ('relu0', nn.ReLU(inplace=True)),\n",
    "        ]))\n",
    "        \n",
    "        # Compare with results from first convolution to produce final output\n",
    "        self.last_layer = nn.Sequential(OrderedDict([\n",
    "            ('conv0', nn.Conv2d(num_init_features*2, 1, kernel_size=3, stride=1, padding=1, bias=False)),\n",
    "            ('relu0', nn.ReLU(inplace=True)),\n",
    "            ('norm0', nn.BatchNorm2d(1)),\n",
    "        ]))        \n",
    "        \n",
    "        # Cropping layer\n",
    "        self.crop_size = (-1 * crop_size[0], -1 * crop_size[1])\n",
    "        \n",
    "        # Down-up pair\n",
    "        for i, num_layers in enumerate(block_config):\n",
    "            # Define denseblock\n",
    "            down_block = nn.Sequential(OrderedDict([\n",
    "            ('pool0', nn.AvgPool2d(kernel_size=2, stride=2)),\n",
    "            ('denseblock%d' % (i + 1), _DenseBlock(num_layers=num_layers, num_input_features=num_features,\n",
    "                                bn_size=bn_size, growth_rate=growth_rate, drop_rate=drop_rate)),\n",
    "            ]))\n",
    "            num_features_old = num_features\n",
    "            num_features += num_layers * growth_rate\n",
    "            \n",
    "            # Transition layer is composed of bath-norm, relu, and a conv layer\n",
    "            # Transition layer is not needed for the last denseblock\n",
    "            if i != len(block_config) - 1:\n",
    "                down_block.add_module('norm', nn.BatchNorm2d(num_features))\n",
    "                down_block.add_module('relu', nn.ReLU(inplace=True))\n",
    "                down_block.add_module('conv0', nn.Conv2d(num_features, num_features // 2,\n",
    "                                          kernel_size=1, stride=1, bias=False))\n",
    "                num_features = num_features // 2    \n",
    "            else:\n",
    "                down_block.add_module('final_bn', nn.BatchNorm2d(num_features))\n",
    "            self.down_features.append(down_block)\n",
    "            \n",
    "            # Upsampling block is composed of upsampling, relu, batchnorm, and conv layer.\n",
    "            up_block = nn.Sequential(OrderedDict([('deconv0',nn.Conv2d(num_features_old + num_features, num_features_old + num_features,\n",
    "                                          kernel_size=5, stride=1, bias=False, padding = 2))]))\n",
    "            up_block.add_module('relu_adj0', nn.ReLU(inplace=True))\n",
    "            up_block.add_module('norm_adj0', nn.BatchNorm2d(num_features_old + num_features))\n",
    "\n",
    "            up_block.add_module('deconv1', nn.Conv2d(num_features_old + num_features, num_features_old,\n",
    "                                              kernel_size=1, stride=1, bias=False))\n",
    "            up_block.add_module('relu_adj1', nn.ReLU(inplace=True))\n",
    "            up_block.add_module('norm_adj1', nn.BatchNorm2d(num_features_old))\n",
    "            self.up_features.append(up_block)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        features_save = []\n",
    "        # Apply first layer\n",
    "        features = self.first_layer(x)\n",
    "        features_save.append(features)      \n",
    "        \n",
    "        # Apply second layer\n",
    "        features = self.second_layer(features)\n",
    "        features_save.append(features)            \n",
    "        \n",
    "        # Apply densenet block\n",
    "        for block in self.down_features:\n",
    "            features = block(features)\n",
    "            features_save.append(features)\n",
    "        features = features_save.pop()\n",
    "        \n",
    "        # Recurse\n",
    "        for block_idx in range(len(self.up_features)):\n",
    "            block = self.up_features[-1 - block_idx]\n",
    "            features = F.interpolate(features, scale_factor = 2)\n",
    "            pop_features = features_save.pop()\n",
    "            features = torch.cat([features, pop_features],dim = 1)\n",
    "            features = block(features)\n",
    "            \n",
    "        # \n",
    "        features = F.interpolate(features, scale_factor = 2)\n",
    "        pop_features = features_save.pop()\n",
    "        features = torch.cat([features, pop_features],dim = 1)\n",
    "        features = self.last_layer(features)          \n",
    "        features = F.pad(features, self.crop_size, \"constant\", 0)\n",
    "        return features                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-12T00:33:19.176147Z",
     "start_time": "2018-11-12T00:33:19.134511Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class FresnelNetFull(nn.Module):\n",
    "    def __init__(self, growth_rate=32):\n",
    "        super(self.__class__, self).__init__()\n",
    "        \n",
    "        # Define structures\n",
    "        self.down_features = []\n",
    "        self.up_features = []        \n",
    "        \n",
    "        num_features = 1\n",
    "        #First convolution (convolves to features)\n",
    "        self.first_layer = nn.Sequential(OrderedDict([\n",
    "            ('conv0', nn.Conv2d(num_channels, num_features, kernel_size=50, stride=1, padding=1, bias=False)),\n",
    "            ('norm0', nn.BatchNorm2d(num_features))\n",
    "        ]))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        features_save = []\n",
    "        # Apply first layer\n",
    "        features = self.first_layer(x)\n",
    "        features_save.append(features)      \n",
    "\n",
    "        return features                        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create neural network instance\n",
    "For now, default parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-12T00:35:45.810688Z",
     "start_time": "2018-11-12T00:35:45.769222Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "num_channels = 1\n",
    "crop_size = (0,40)\n",
    "fresnel_net = FresnelNet(num_channels = num_channels, crop_size = crop_size, block_config=[])\n",
    "if use_cuda:\n",
    "    fresnel_net = fresnel_net.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-12T00:35:48.552560Z",
     "start_time": "2018-11-12T00:35:48.514261Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fresnel_data = FresnelDataset(data_full)\n",
    "dataloader   = DataLoader(fresnel_data, batch_size=10, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define cost function & optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-12T00:35:49.191031Z",
     "start_time": "2018-11-12T00:35:49.154356Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.SGD(fresnel_net.parameters(), lr=0.001, momentum=0.9)\n",
    "# optimizer = optim.Adam(fresnel_net.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-12T01:10:33.475730Z",
     "start_time": "2018-11-12T00:35:50.617740Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished epoch 0, time used: 1745.022634, error: 48.994194\n",
      "Finished Training, time used: 1745.022742379\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 1\n",
    "with contexttimer.Timer() as timer:\n",
    "    for epoch in range(num_epochs):  # loop over the dataset multiple times\n",
    "        running_loss = 0.0\n",
    "        for i, data in enumerate(dataloader, 0):\n",
    "            # get the inputs\n",
    "            inputs, labels = data\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "            # forward + backward + optimize\n",
    "            if use_cuda:\n",
    "                \n",
    "                inputs = inputs.cuda()\n",
    "                labels = labels.cuda()\n",
    "            outputs = fresnel_net(inputs)\n",
    "#             print(outputs.shape)\n",
    "\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            del outputs\n",
    "            if use_cuda:\n",
    "                torch.cuda.empty_cache()\n",
    "        print('Finished epoch %d, time used: %f, error: %f' % (epoch, timer.elapsed, running_loss))\n",
    "    print('Finished Training, time used:', timer.elapsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-11T23:51:54.495358Z",
     "start_time": "2018-11-11T23:51:54.467882Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'outputs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-48066930c5f4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0moutdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0minputdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mlabeldata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'outputs' is not defined"
     ]
    }
   ],
   "source": [
    "outdata = outputs.cpu().detach().numpy()\n",
    "inputdata = inputs.cpu().detach().numpy()\n",
    "labeldata = labels.cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "outdata.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "plt.subplot(131)\n",
    "plt.imshow(np.squeeze(np.real(inputdata)[3,:,:,:]))\n",
    "plt.title('input')\n",
    "plt.subplot(132)\n",
    "plt.imshow(np.squeeze(np.real(labeldata)[3,:,:,:]))\n",
    "plt.title('ground truth')\n",
    "plt.subplot(133)\n",
    "plt.imshow(np.squeeze(np.real(outdata)[3,:,:,:]))\n",
    "plt.title('output')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "torch.save(fresnel_net, output_directory+'network.pth.tar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import scipy.io as sio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results = {\"input\": np.real(inputdata), \"gt\": np.real(labeldata), \"output\": np.real(outdata)}\n",
    "sio.savemat(\"results.mat\", results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

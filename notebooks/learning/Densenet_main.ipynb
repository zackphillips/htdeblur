{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-11T23:57:02.565308Z",
     "start_time": "2018-11-11T23:57:02.464398Z"
    }
   },
   "outputs": [],
   "source": [
    "# Decorators\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib notebook\n",
    "\n",
    "use_cuda = False\n",
    "#General\n",
    "import torch\n",
    "import os, glob\n",
    "\n",
    "if use_cuda:\n",
    "    torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
    "import torchvision\n",
    "import numpy as np\n",
    "\n",
    "#Used for data\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "#Used to define densenet\n",
    "import torch.nn as nn\n",
    "from torchvision import models\n",
    "from torchvision.models.densenet import DenseNet\n",
    "from torchvision.models.densenet import OrderedDict\n",
    "from torchvision.models.densenet import _DenseBlock\n",
    "from torchvision.models.densenet import _DenseLayer\n",
    "from torchvision.models.densenet import _Transition\n",
    "import torch.nn.functional as F\n",
    "\n",
    "#Used for optimization\n",
    "import torch.optim as optim\n",
    "\n",
    "#timing\n",
    "import contexttimer\n",
    "\n",
    "# Data directory\n",
    "data_dir = '/Users/zfphil/datasets/motiondeblur/learning_data/'\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-11T23:57:02.957006Z",
     "start_time": "2018-11-11T23:57:02.858116Z"
    }
   },
   "outputs": [],
   "source": [
    "class FresnelNet(nn.Module):\n",
    "    def __init__(self, growth_rate=32, block_config=(6, 12, 24, 16),\n",
    "                 num_init_features=64, bn_size=4, drop_rate=0, num_classes=1000, num_channels = 3, crop_size = (0,0)):\n",
    "        super(FresnelNet, self).__init__()\n",
    "        # Define structures\n",
    "        self.down_features = []\n",
    "        self.up_features = []        \n",
    "        \n",
    "        num_features = num_init_features\n",
    "        #First convolution (convolves to features)\n",
    "        self.first_layer = nn.Sequential(OrderedDict([\n",
    "            ('conv0', nn.Conv2d(num_channels, num_features, kernel_size=7, stride=1, padding=3, bias=False)),\n",
    "            ('norm0', nn.BatchNorm2d(num_features)),\n",
    "            ('relu0', nn.ReLU(inplace=True)),\n",
    "            ('conv1', nn.Conv2d(num_features, num_features, kernel_size=3, stride=1, padding=1, bias=False)),\n",
    "            ('norm1', nn.BatchNorm2d(num_features)),\n",
    "            ('relu1', nn.ReLU(inplace=True)),            \n",
    "        ]))\n",
    "        # Convolve again to reduce size\n",
    "        self.second_layer = nn.Sequential(OrderedDict([\n",
    "            ('conv0', nn.Conv2d(num_features, num_features, kernel_size=3, stride=2, padding=1, bias=False)),\n",
    "            ('norm0', nn.BatchNorm2d(num_features)),\n",
    "            ('relu0', nn.ReLU(inplace=True)),\n",
    "        ]))\n",
    "        \n",
    "        # Compare with results from first convolution to produce final output\n",
    "        self.last_layer = nn.Sequential(OrderedDict([\n",
    "            ('conv0', nn.Conv2d(num_init_features*2, 1, kernel_size=3, stride=1, padding=1, bias=False)),\n",
    "            ('relu0', nn.ReLU(inplace=True)),\n",
    "            ('norm0', nn.BatchNorm2d(1)),\n",
    "        ]))        \n",
    "        \n",
    "        # Cropping layer\n",
    "        self.crop_size = (-1 * crop_size[0], -1 * crop_size[1])\n",
    "        \n",
    "        # Down-up pair\n",
    "        for i, num_layers in enumerate(block_config):\n",
    "            # Define denseblock\n",
    "            down_block = nn.Sequential(OrderedDict([\n",
    "            ('pool0', nn.AvgPool2d(kernel_size=2, stride=2)),\n",
    "            ('denseblock%d' % (i + 1), _DenseBlock(num_layers=num_layers, num_input_features=num_features,\n",
    "                                bn_size=bn_size, growth_rate=growth_rate, drop_rate=drop_rate)),\n",
    "            ]))\n",
    "            num_features_old = num_features\n",
    "            num_features += num_layers * growth_rate\n",
    "            \n",
    "            # Transition layer is composed of bath-norm, relu, and a conv layer\n",
    "            # Transition layer is not needed for the last denseblock\n",
    "            if i != len(block_config) - 1:\n",
    "                down_block.add_module('norm', nn.BatchNorm2d(num_features))\n",
    "                down_block.add_module('relu', nn.ReLU(inplace=True))\n",
    "                down_block.add_module('conv0', nn.Conv2d(num_features, num_features // 2,\n",
    "                                          kernel_size=1, stride=1, bias=False))\n",
    "                num_features = num_features // 2    \n",
    "            else:\n",
    "                down_block.add_module('final_bn', nn.BatchNorm2d(num_features))\n",
    "            self.down_features.append(down_block)\n",
    "            \n",
    "            # Upsampling block is composed of upsampling, relu, batchnorm, and conv layer.\n",
    "            up_block = nn.Sequential(OrderedDict([('deconv0',nn.Conv2d(num_features_old + num_features, num_features_old + num_features,\n",
    "                                          kernel_size=5, stride=1, bias=False, padding = 2))]))\n",
    "            up_block.add_module('relu_adj0', nn.ReLU(inplace=True))\n",
    "            up_block.add_module('norm_adj0', nn.BatchNorm2d(num_features_old + num_features))\n",
    "\n",
    "            up_block.add_module('deconv1', nn.Conv2d(num_features_old + num_features, num_features_old,\n",
    "                                              kernel_size=1, stride=1, bias=False))\n",
    "            up_block.add_module('relu_adj1', nn.ReLU(inplace=True))\n",
    "            up_block.add_module('norm_adj1', nn.BatchNorm2d(num_features_old))\n",
    "            self.up_features.append(up_block)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        features_save = []\n",
    "        features = self.first_layer(x)\n",
    "#         print(features.shape)\n",
    "        features_save.append(features)            \n",
    "        features = self.second_layer(features)\n",
    "#         print(features.shape)\n",
    "        features_save.append(features)            \n",
    "\n",
    "        for block in self.down_features:\n",
    "            features = block(features)\n",
    "#             print(features.shape)\n",
    "            features_save.append(features)\n",
    "        features = features_save.pop()\n",
    "        \n",
    "        for block_idx in range(len(self.up_features)):\n",
    "            block = self.up_features[-1 - block_idx]\n",
    "            features = F.interpolate(features, scale_factor = 2)\n",
    "            pop_features = features_save.pop()\n",
    "            features = torch.cat([features, pop_features],dim = 1)\n",
    "            features = block(features)\n",
    "        features = F.interpolate(features, scale_factor = 2)\n",
    "        pop_features = features_save.pop()\n",
    "        features = torch.cat([features, pop_features],dim = 1)\n",
    "        features = self.last_layer(features)          \n",
    "        features = F.pad(features, self.crop_size, \"constant\", 0)\n",
    "        return features                        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create neural network instance\n",
    "For now, default parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-11T23:57:04.083991Z",
     "start_time": "2018-11-11T23:57:03.398474Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "num_channels = 1\n",
    "crop_size = (0,40)\n",
    "fresnel_net = FresnelNet(num_channels = num_channels, crop_size = crop_size)\n",
    "if use_cuda:\n",
    "    fresnel_net = fresnel_net.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-11T23:57:04.166038Z",
     "start_time": "2018-11-11T23:57:04.085877Z"
    }
   },
   "outputs": [],
   "source": [
    "class FresnelDataset(Dataset):\n",
    "    def __init__(self, data, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        self.transform = transform\n",
    "        self.data = data\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-11T23:57:45.684831Z",
     "start_time": "2018-11-11T23:57:05.096188Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define output directory\n",
    "output_directory = \"%s/%s\"   % (os.getcwd(), \"data/learning_data/\")\n",
    "print(output_directory)\n",
    "# Find frames\n",
    "files = list(glob.glob(data_dir + '*.npz'))\n",
    "assert len(files) > 0\n",
    "files.sort()\n",
    "data_full = []\n",
    "for frame_index in range(len(files)):    \n",
    "    # Load data point (second line deals with weird structuring of .npz files)\n",
    "    _data = dict(np.load(files[frame_index]))\n",
    "    data = {key:_data[key].item() for key in _data}['arr_0']\n",
    "\n",
    "    input_data = np.real(data['measurements'][0]['array']).astype('float32')\n",
    "    output_data = np.real(data['ground_truth']['array']).astype('float32')\n",
    "    data_pair = (input_data[np.newaxis,0:128,0:128], output_data[np.newaxis,0:128,0:88])\n",
    "    data_full.append(data_pair)\n",
    "    if frame_index % 100 == 0:\n",
    "        print('Loaded file %d' % (frame_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-11T23:57:52.387834Z",
     "start_time": "2018-11-11T23:57:52.302419Z"
    }
   },
   "outputs": [],
   "source": [
    "fresnel_data = FresnelDataset(data_full)\n",
    "dataloader   = DataLoader(fresnel_data, batch_size=10, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define cost function & optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-11T23:57:54.019954Z",
     "start_time": "2018-11-11T23:57:53.933272Z"
    }
   },
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()\n",
    "# optimizer = optim.SGD(fresnel_net.parameters(), lr=0.001, momentum=0.9)\n",
    "optimizer = optim.Adam(fresnel_net.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-11-11T23:58:10.106Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "num_epochs = 1\n",
    "with contexttimer.Timer() as timer:\n",
    "    for epoch in range(num_epochs):  # loop over the dataset multiple times\n",
    "        running_loss = 0.0\n",
    "        for i, data in enumerate(dataloader, 0):\n",
    "            # get the inputs\n",
    "            inputs, labels = data\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "            # forward + backward + optimize\n",
    "            if use_cuda:\n",
    "                inputs = inputs.cuda()\n",
    "                labels = labels.cuda()\n",
    "            outputs = fresnel_net(inputs)\n",
    "#             print(outputs.shape)\n",
    "\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            del outputs\n",
    "            if use_cuda:\n",
    "                torch.cuda.empty_cache()\n",
    "        print('Finished epoch %d, time used: %f, error: %f' % (epoch, timer.elapsed, running_loss))\n",
    "    print('Finished Training, time used:', timer.elapsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-11T23:51:51.366833Z",
     "start_time": "2018-11-11T23:51:51.340441Z"
    }
   },
   "outputs": [],
   "source": [
    "outputs = fresnel_net(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-11T23:51:54.495358Z",
     "start_time": "2018-11-11T23:51:54.467882Z"
    }
   },
   "outputs": [],
   "source": [
    "outdata = outputs.cpu().detach().numpy()\n",
    "inputdata = inputs.cpu().detach().numpy()\n",
    "labeldata = labels.cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outdata.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "plt.subplot(131)\n",
    "plt.imshow(np.squeeze(np.real(inputdata)[3,:,:,:]))\n",
    "plt.title('input')\n",
    "plt.subplot(132)\n",
    "plt.imshow(np.squeeze(np.real(labeldata)[3,:,:,:]))\n",
    "plt.title('ground truth')\n",
    "plt.subplot(133)\n",
    "plt.imshow(np.squeeze(np.real(outdata)[3,:,:,:]))\n",
    "plt.title('output')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(fresnel_net, output_directory+'network.pth.tar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io as sio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {\"input\": np.real(inputdata), \"gt\": np.real(labeldata), \"output\": np.real(outdata)}\n",
    "sio.savemat(\"results.mat\", results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

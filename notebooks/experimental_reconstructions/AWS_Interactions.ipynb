{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-28T19:07:57.510950Z",
     "start_time": "2019-01-28T19:07:55.912674Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: paramiko in /Users/zfphil/.conda/lib/python3.7/site-packages (2.4.2)\n",
      "Requirement already satisfied: boto in /Users/zfphil/.conda/lib/python3.7/site-packages (2.49.0)\n",
      "Requirement already satisfied: boto3 in /Users/zfphil/.conda/lib/python3.7/site-packages (1.9.69)\n",
      "Requirement already satisfied: pyasn1>=0.1.7 in /Users/zfphil/.conda/lib/python3.7/site-packages (from paramiko) (0.4.4)\n",
      "Requirement already satisfied: pynacl>=1.0.1 in /Users/zfphil/.conda/lib/python3.7/site-packages (from paramiko) (1.3.0)\n",
      "Requirement already satisfied: bcrypt>=3.1.3 in /Users/zfphil/.conda/lib/python3.7/site-packages (from paramiko) (3.1.5)\n",
      "Requirement already satisfied: cryptography>=1.5 in /Users/zfphil/.conda/lib/python3.7/site-packages (from paramiko) (2.3.1)\n",
      "Requirement already satisfied: s3transfer<0.2.0,>=0.1.10 in /Users/zfphil/.conda/lib/python3.7/site-packages (from boto3) (0.1.13)\n",
      "Requirement already satisfied: botocore<1.13.0,>=1.12.69 in /Users/zfphil/.conda/lib/python3.7/site-packages (from boto3) (1.12.69)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /Users/zfphil/.conda/lib/python3.7/site-packages (from boto3) (0.9.3)\n",
      "Requirement already satisfied: cffi>=1.4.1 in /Users/zfphil/.conda/lib/python3.7/site-packages (from pynacl>=1.0.1->paramiko) (1.11.5)\n",
      "Requirement already satisfied: six in /Users/zfphil/.conda/lib/python3.7/site-packages (from pynacl>=1.0.1->paramiko) (1.11.0)\n",
      "Requirement already satisfied: idna>=2.1 in /Users/zfphil/.conda/lib/python3.7/site-packages (from cryptography>=1.5->paramiko) (2.7)\n",
      "Requirement already satisfied: asn1crypto>=0.21.0 in /Users/zfphil/.conda/lib/python3.7/site-packages (from cryptography>=1.5->paramiko) (0.24.0)\n",
      "Requirement already satisfied: docutils>=0.10 in /Users/zfphil/.conda/lib/python3.7/site-packages (from botocore<1.13.0,>=1.12.69->boto3) (0.14)\n",
      "Requirement already satisfied: urllib3<1.25,>=1.20; python_version >= \"3.4\" in /Users/zfphil/.conda/lib/python3.7/site-packages (from botocore<1.13.0,>=1.12.69->boto3) (1.23)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\" in /Users/zfphil/.conda/lib/python3.7/site-packages (from botocore<1.13.0,>=1.12.69->boto3) (2.7.5)\n",
      "Requirement already satisfied: pycparser in /Users/zfphil/.conda/lib/python3.7/site-packages (from cffi>=1.4.1->pynacl>=1.0.1->paramiko) (2.18)\n",
      "\u001b[33mYou are using pip version 18.1, however version 19.0.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install paramiko boto boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-28T19:07:58.597720Z",
     "start_time": "2019-01-28T19:07:58.301610Z"
    }
   },
   "outputs": [],
   "source": [
    "import aws_helper as a # this python file has a bunch of messy thrown-together\n",
    "                       # methods using boto3 libraries with amazon and a ssh python interface\n",
    "                       # called paramiko\n",
    "import threading\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-28T19:08:26.941609Z",
     "start_time": "2019-01-28T19:08:26.937951Z"
    }
   },
   "outputs": [],
   "source": [
    "## Instance Parameters\n",
    "\n",
    "MD_AMI = \"ami-02db52e359e89b39d\" # this AMI should have up-to-date libwallerlab\n",
    "                                 # it also needs to have aws client installed and configured with\n",
    "                                 # credentials\n",
    "                                 # old ami: \"ami-0f6e873188b7105e6\"\n",
    "INSTANCE_TYPE = \"p2.xlarge\"  # \"p2.xlarge\" \"t2.micro\" \"r5a.2xlarge\"\n",
    "                               # p2 is GPU instance for deblurring, \n",
    "                               # t2 is cheap, good for testing basic stuff\n",
    "                               # r5 has lots of memory, good for stitching\n",
    "KEYNAME = \"p2xps\" # this is the name of the key on Amazon (if you launch an instance manually)\n",
    "                  # through the console, you will be prompted to create and download keypairs\n",
    "# KEYPATH = '/home/sarah/.ssh/p2xps.pem' # this is the location of the key on your computer\n",
    "KEYPATH = os.path.expanduser('~/.ssh/p2xps.pem') # this is the location of the key on your computer\n",
    "\n",
    "PRICE = '0.4' # for spot instances\n",
    "num_instances = 1 # the number of instances\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-28T19:08:49.212494Z",
     "start_time": "2019-01-28T19:08:49.002229Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ClientError",
     "evalue": "An error occurred (InvalidGroup.NotFound) when calling the RequestSpotInstances operation: The security group 'sg-0f5165083df8e479f' does not exist in VPC 'vpc-4864b730'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mClientError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-640451752be5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0minstance_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mpublic_dnses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_instances\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0minstance_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpublic_dns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_instance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMD_AMI\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPRICE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mKEYNAME\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mINSTANCE_TYPE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'id:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minstance_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'dns:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpublic_dns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/develop/libwallerlab/libwallerlab/projects/motiondeblur/experimental_reconstructions/aws_helper.py\u001b[0m in \u001b[0;36mstart_instance\u001b[0;34m(ami, price, keyname, instance_type, start_script)\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0mInstanceCount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0mType\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'one-time'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m         LaunchSpecification=launch_specification)\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0mrequest_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'SpotInstanceRequests'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'SpotInstanceRequestId'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/lib/python3.7/site-packages/botocore/client.py\u001b[0m in \u001b[0;36m_api_call\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    318\u001b[0m                     \"%s() only accepts keyword arguments.\" % py_operation_name)\n\u001b[1;32m    319\u001b[0m             \u001b[0;31m# The \"self\" in this scope is referring to the BaseClient.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 320\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_api_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moperation_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    321\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m         \u001b[0m_api_call\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpy_operation_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/lib/python3.7/site-packages/botocore/client.py\u001b[0m in \u001b[0;36m_make_api_call\u001b[0;34m(self, operation_name, api_params)\u001b[0m\n\u001b[1;32m    622\u001b[0m             \u001b[0merror_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsed_response\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Error\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Code\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    623\u001b[0m             \u001b[0merror_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_code\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 624\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0merror_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparsed_response\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moperation_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    625\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    626\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mparsed_response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mClientError\u001b[0m: An error occurred (InvalidGroup.NotFound) when calling the RequestSpotInstances operation: The security group 'sg-0f5165083df8e479f' does not exist in VPC 'vpc-4864b730'"
     ]
    }
   ],
   "source": [
    "## Starting spot requests\n",
    "\n",
    "instance_ids = []; public_dnses = []\n",
    "for i in range(num_instances):\n",
    "    instance_id, public_dns = a.start_instance(MD_AMI, PRICE, KEYNAME, INSTANCE_TYPE)\n",
    "    print('id:', instance_id)\n",
    "    print('dns:', public_dns)\n",
    "    instance_ids.append(instance_id); \n",
    "    public_dnses.append(public_dns)\n",
    "    \n",
    "    \n",
    "# TODO current there is a bug in the way instances IDs are collected, so the list might not be accurate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-20T18:57:08.587929Z",
     "start_time": "2018-12-20T18:57:05.889Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['ec2-54-244-162-28.us-west-2.compute.amazonaws.com'], ['ec2-54-149-145-243.us-west-2.compute.amazonaws.com']]\n",
      "ec2-54-244-162-28.us-west-2.compute.amazonaws.com\n",
      "ec2-54-149-145-243.us-west-2.compute.amazonaws.com\n",
      "['ec2-54-244-162-28.us-west-2.compute.amazonaws.com', 'ec2-54-149-145-243.us-west-2.compute.amazonaws.com']\n"
     ]
    }
   ],
   "source": [
    "## Collecting DNS of all open instances\n",
    "\n",
    "instance_list = a.get_all_instances()\n",
    "print(instance_list)\n",
    "public_dnses = []\n",
    "for instance in instance_list: # instance_list[0]\n",
    "    print(instance[0])\n",
    "    if instance[0] != '': # instance != '':\n",
    "        public_dnses.append(instance[0])\n",
    "print(public_dnses)\n",
    "\n",
    "# TODO sometimes the returned list is buggy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-20T18:57:08.588646Z",
     "start_time": "2018-12-20T18:57:05.890Z"
    }
   },
   "outputs": [],
   "source": [
    "# if all else fails, manually collect DNS from ec2 console (under \"Instances\") -- make sure the \n",
    "# region is correct because the console only shows instances in a given region (us-west-2 is my default)\n",
    "\n",
    "# public_dnses = ['ec2-54-202-61-221.us-west-2.compute.amazonaws.com', \n",
    "#                 'ec2-54-212-219-53.us-west-2.compute.amazonaws.com',\n",
    "#                'ec2-34-208-98-113.us-west-2.compute.amazonaws.com',\n",
    "#                'ec2-34-222-213-10.us-west-2.compute.amazonaws.com']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-20T18:57:08.589459Z",
     "start_time": "2018-12-20T18:57:05.892Z"
    }
   },
   "outputs": [],
   "source": [
    "# Sending commands to instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-20T18:57:08.590614Z",
     "start_time": "2018-12-20T18:57:05.893Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "res_target_color_coded_raster_motiondeblur_2018_05_22_19_17_45\n",
      "res_target_color_strobe_raster_motiondeblur_2018_05_22_19_17_18_recovered_[19, 20, 21, 22, 23].npz\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Show all datasets loaded onto each instance\n",
    "\n",
    "outlock = threading.Lock()\n",
    "\n",
    "test_cmd = 'cd ~/datasets; ls' #; sleep 5'\n",
    "\n",
    "threads = []\n",
    "for i in range(num_instances): #num_instances):\n",
    "    t = threading.Thread(target=a.send_command_to_instance, args=(test_cmd, public_dnses[i], KEYPATH))\n",
    "    t.start()\n",
    "    threads.append(t)\n",
    "for t in threads:\n",
    "    t.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-20T18:57:08.591954Z",
     "start_time": "2018-12-20T18:57:05.895Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Copying datasets from s3 to instance\n",
    "\n",
    "outlock = threading.Lock()\n",
    "\n",
    "filename = '163c_color_coded_raster_motiondeblur_2018_05_23_08_50_25'\n",
    "filename = '163a_color_coded_raster_motiondeblur_2018_05_22_21_47_35'\n",
    "filename = '174d_color_coded_raster_motiondeblur_2018_05_23_16_18_15'\n",
    "\n",
    "# TODO the below method of string construction for some reason does not work...\n",
    "copy_file = 'aws s3 cp s3://motiondeblur/ ' + filename + '/ ~/datasets/' + filename + ' --recursive --region us-east-2'\n",
    "\n",
    "copy_file_163c = 'aws s3 cp s3://motiondeblur/163c_color_coded_raster_motiondeblur_2018_05_23_08_50_25/ ~/datasets/163c_color_coded_raster_motiondeblur_2018_05_23_08_50_25 --recursive --region us-east-2'\n",
    "copy_file_163a = 'aws s3 cp s3://motiondeblur/163a_color_coded_raster_motiondeblur_2018_05_22_21_47_35/ ~/datasets/163a_color_coded_raster_motiondeblur_2018_05_22_21_47_35 --recursive --region us-east-2'\n",
    "copy_file_174d = 'aws s3 cp s3://motiondeblur/174d_color_coded_raster_motiondeblur_2018_05_23_16_18_15/ ~/datasets/174d_color_coded_raster_motiondeblur_2018_05_23_16_18_15 --recursive --region us-east-2'\n",
    "\n",
    "\n",
    "copy_file = 'aws s3 cp s3://motiondeblur/beads_coded_raster_100/ ~/datasets/beads_coded_raster_100 --recursive --region us-east-2'\n",
    "\n",
    "\n",
    "threads = []\n",
    "for i in range(num_instances):\n",
    "    if i in [0,1,2]: # logic about which datasets to which instance\n",
    "        cmd = 'rm -rf ~/datasets/*; ' + copy_file_163a\n",
    "    elif i in [3,4,5]:\n",
    "        cmd = 'rm -rf ~/datasets/*; ' + copy_file_174d\n",
    "    t = threading.Thread(target=a.send_command_to_instance, args=(cmd, public_dnses[i], KEYPATH))\n",
    "    t.start()\n",
    "    threads.append(t)\n",
    "for t in threads:\n",
    "    t.join()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-20T18:57:08.592714Z",
     "start_time": "2018-12-20T18:57:05.897Z"
    }
   },
   "outputs": [],
   "source": [
    "## Running reconstructions on each instance\n",
    "\n",
    "outlock = threading.Lock()\n",
    "\n",
    "# note: by default instance open to home directory, so it is necessary to cd into correct directory\n",
    "change_dir = 'cd /home/ubuntu/libwallerlab/libwallerlab/projects/motiondeblur/experimental_reconstructions; '\n",
    "\n",
    "# the script run_recons.sh calls the reconstruction python script\n",
    "reconstruct = [\"./run_recons.sh 0 29 coded_163a.conf '--channel 0' > output.txt; \",\n",
    "               \"./run_recons.sh 0 29 coded_163a.conf '--channel 1' > output.txt; \",\n",
    "               \"./run_recons.sh 0 29 coded_163a.conf '--channel 2' > output.txt; \",\n",
    "               \"./run_recons.sh 0 29 coded_174d.conf '--channel 0' > output.txt; \",\n",
    "               \"./run_recons.sh 0 29 coded_174d.conf '--channel 1' > output.txt; \",\n",
    "               \"./run_recons.sh 0 29 coded_174d.conf '--channel 2' > output.txt; \"]\n",
    "\n",
    "threads_recon = []\n",
    "for i in range(num_instances):\n",
    "    cmd = change_dir + reconstruct[i]\n",
    "    t = threading.Thread(target=a.send_command_to_instance, args=(cmd, public_dnses[i], KEYPATH))\n",
    "    t.start()\n",
    "    threads_recon.append(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-20T18:57:08.593450Z",
     "start_time": "2018-12-20T18:57:05.898Z"
    }
   },
   "outputs": [],
   "source": [
    "# Calling t.join() here waits until all reconstructions are done -- usually I don't run this cell\n",
    "\n",
    "for t in threads_recon:\n",
    "    t.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-20T18:57:08.595209Z",
     "start_time": "2018-12-20T18:57:05.900Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## Checking the status of recons on each instance based on the file output.txt\n",
    "\n",
    "# prints output of reconstruction script\n",
    "# outputs update after each frame\n",
    "\n",
    "outlock = threading.Lock()\n",
    "\n",
    "change_dir = 'cd /home/ubuntu/libwallerlab/libwallerlab/projects/motiondeblur/experimental_reconstructions; '\n",
    "status = 'cat output.txt'\n",
    "\n",
    "threads = []\n",
    "for i in range(num_instances):\n",
    "    cmd = change_dir + status\n",
    "    t = threading.Thread(target=a.send_command_to_instance, args=(cmd, public_dnses[i], KEYPATH))\n",
    "    t.start()\n",
    "    threads.append(t)\n",
    "for t in threads:\n",
    "    t.join()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-28T19:08:40.591655Z",
     "start_time": "2019-01-28T19:08:40.582133Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'public_dns' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-86c942c6d788>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m## Copying reconstructed strips to instance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mpublic_dns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpublic_dns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;31m# copy_files = 'aws s3 cp s3://motiondeblur/reconstructions/ ./ --recursive --exclude \"*\" --include \"163c_color_coded_raster_motiondeblur_2018_05_23_08_50_25_strip*_channel=1*\" --region us-east-2'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mcopy_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'aws s3 cp s3://motiondeblur/reconstructions/ ./ --recursive --exclude \"*\" --include \"beads_*\" --region us-east-2'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'public_dns' is not defined"
     ]
    }
   ],
   "source": [
    "## Copying reconstructed strips to instance\n",
    "\n",
    "public_dns = public_dns[0]\n",
    "# copy_files = 'aws s3 cp s3://motiondeblur/reconstructions/ ./ --recursive --exclude \"*\" --include \"163c_color_coded_raster_motiondeblur_2018_05_23_08_50_25_strip*_channel=1*\" --region us-east-2'\n",
    "copy_files = 'aws s3 cp s3://motiondeblur/reconstructions/ ./ --recursive --exclude \"*\" --include \"beads_*\" --region us-east-2'\n",
    "cmd = 'cd ~/reconstructions; ' + copy_files # + 'ls ~/datasets'\n",
    "a.send_command_to_instance(cmd, public_dns, KEYPATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-28T19:10:21.472248Z",
     "start_time": "2019-01-28T19:10:21.447590Z"
    }
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'aws s3 cp s3://motiondeblur/reconstructions/ ./ --recursive --exclude \"*\" --include \"beads_*\" --region us-east-2': 'aws s3 cp s3://motiondeblur/reconstructions/ ./ --recursive --exclude \"*\" --include \"beads_*\" --region us-east-2'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-3aa5b17ec897>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mcmd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'cd ~/datasets; '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mcopy_files\u001b[0m \u001b[0;31m# + 'ls ~/datasets'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msubprocess\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0msubprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcopy_files\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.conda/lib/python3.7/subprocess.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    464\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'stderr'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPIPE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 466\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mPopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mpopenargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mprocess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    467\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    468\u001b[0m             \u001b[0mstdout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstderr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommunicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/lib/python3.7/subprocess.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, encoding, errors, text)\u001b[0m\n\u001b[1;32m    767\u001b[0m                                 \u001b[0mc2pread\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc2pwrite\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    768\u001b[0m                                 \u001b[0merrread\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrwrite\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 769\u001b[0;31m                                 restore_signals, start_new_session)\n\u001b[0m\u001b[1;32m    770\u001b[0m         \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    771\u001b[0m             \u001b[0;31m# Cleanup if the child failed starting.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/lib/python3.7/subprocess.py\u001b[0m in \u001b[0;36m_execute_child\u001b[0;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, restore_signals, start_new_session)\u001b[0m\n\u001b[1;32m   1514\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0merrno_num\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0merrno\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mENOENT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1515\u001b[0m                             \u001b[0merr_msg\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m': '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mrepr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1516\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mchild_exception_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merrno_num\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr_msg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1517\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mchild_exception_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr_msg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1518\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'aws s3 cp s3://motiondeblur/reconstructions/ ./ --recursive --exclude \"*\" --include \"beads_*\" --region us-east-2': 'aws s3 cp s3://motiondeblur/reconstructions/ ./ --recursive --exclude \"*\" --include \"beads_*\" --region us-east-2'"
     ]
    }
   ],
   "source": [
    "## Copying reconstructed strips to instance\n",
    "\n",
    "# copy_files = 'aws s3 cp s3://motiondeblur/reconstructions/ ./ --recursive --exclude \"*\" --include \"163c_color_coded_raster_motiondeblur_2018_05_23_08_50_25_strip*_channel=1*\" --region us-east-2'\n",
    "copy_files = 'aws s3 cp s3://motiondeblur/reconstructions/ ./ --recursive --exclude \"*\" --include \"beads_*\" --region us-east-2'\n",
    "cmd = 'cd ~/datasets; ' + copy_files # + 'ls ~/datasets'\n",
    "import subprocess\n",
    "subprocess.run([copy_files, \"\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-20T18:57:08.598847Z",
     "start_time": "2018-12-20T18:57:05.902Z"
    }
   },
   "outputs": [],
   "source": [
    "## Stitching all strips on instance\n",
    "\n",
    "# I usually do this via jupyter notebook batch_segment_stitching_aws.ipynb:\n",
    "# 1) manually ssh into machine with `ssh -i PATH_TO_KEY ubuntu@PUBLIC_DNS`\n",
    "# 2) get jupyter notebook up and running in a screen: `screen -S notebook` then `jupyter notebook` \n",
    "#    usually from libwallerlab directory so I can edit any necessary code through the notebook interfact\n",
    "#    the screen can be detached with ctrl+a d, and reattached with `screen -r notebook`\n",
    "#    allowing you to do multiple things at once on the instance. Note the token that appears when the \n",
    "#    notebook server starts running -- you'll need this to log in\n",
    "# 3) on your own computer, start an ssh pipe: \n",
    "#    `ssh -i PATH_TO_KEY -N -L 8080:localhost:8888 ubuntu@PUBLIC_DNS\n",
    "#    [this assumes the jupyter notebook on the machine is at port 8888]\n",
    "# 4) go to localhost:8080 and enter the token\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

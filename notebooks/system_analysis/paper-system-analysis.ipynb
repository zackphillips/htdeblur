{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-13T17:03:17.491532Z",
     "start_time": "2018-12-13T17:03:13.192719Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from libwallerlab.projects.motiondeblur import blurkernel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview\n",
    "This notebook explores a SNR vs. acquisition time analysis for strobed illumination, stop and stare, and coded illumination acquisition strategies.\n",
    "\n",
    "First, we determine a relationship between t_frame (frame rate) and t_exposure (exposure time). Then, we relate t_exposure to SNR for each method. These relationships should be smooth but non-linear."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-13T17:03:17.517884Z",
     "start_time": "2018-12-13T17:03:17.493791Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define constants\n",
    "ps = 6.5e-3 #mm\n",
    "mag = 10\n",
    "ps_eff_mm = ps / mag #um\n",
    "n_px = np.asarray([2180, 2580])\n",
    "fov = n_px * ps_eff_mm\n",
    "motion_axis = 0\n",
    "motion_velocity_mm_s = 25\n",
    "motion_acceleration_mm_s_s = 1e4\n",
    "\n",
    "t_settle = 0.1   #s\n",
    "t_ro     = 0.01  #s\n",
    "\n",
    "figure_directory = '/Users/zfphil/Dropbox/Berkeley/My Papers/[2018-12] MD Paper/figures/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Limiting Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters of interest:\n",
    "- Maximum SNR\n",
    "- Maximum frame rate\n",
    "\n",
    "## Camera\n",
    "- full-well capacity: maximum exposure time (imaging SNR)\n",
    "- readout time: maximum exposure time (imaging SNR)\n",
    "\n",
    "## LED Array\n",
    "- led update rate: Limits motion velocity\n",
    "- led intensity: \n",
    "\n",
    "## Motion Stage\n",
    "- Maximum Velocity\n",
    "- Maximum Acceleration\n",
    "- Settle time\n",
    "\n",
    "## Imaging Optics\n",
    "- Field of view\n",
    "- Radiance collected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-13T17:03:17.541067Z",
     "start_time": "2018-12-13T17:03:17.519278Z"
    }
   },
   "outputs": [],
   "source": [
    "# Given frame rate\n",
    "\n",
    "# 1. determine exposure time for strobe / coded\n",
    "# 2. determine exposir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-13T18:43:15.764351Z",
     "start_time": "2018-12-13T18:43:15.704780Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Strobed illumination at 25 fps will have photon output 1.625e-05 seconds and SNR 6.18015 (dnf = 1)\n",
      "Stop-and-stare illumination at 25 fps will have photon output 0.0114686 seconds and SNR 173.191 (dnf = 1)\n",
      "0.50 Coded illumination at 25 fps will have photon output 0.00573625 seconds and SNR 2.75681 (dnf = 44.4265)\n",
      "0.10 Coded illumination at 25 fps will have photon output 0.00115375 seconds and SNR 3.11405 (dnf = 17.6275)\n",
      "0.05 Coded illumination at 25 fps will have photon output 0.00056875 seconds and SNR 2.8512 (dnf = 13.5064)\n",
      "0.01 Coded illumination at 25 fps will have photon output 0.00011375 seconds and SNR 3.62981 (dnf = 4.71435)\n"
     ]
    }
   ],
   "source": [
    "def calcDnfFromKernel(x):\n",
    "    x = x / np.sum(x)\n",
    "    if len(x) == 0:\n",
    "        return np.inf\n",
    "    elif np.min(np.abs(np.fft.fft(x)) ** 2) == 0:\n",
    "        return np.inf\n",
    "    else:\n",
    "        return np.sqrt(1 / len(x) * np.sum(1 / np.abs(np.fft.fft(x)) ** 2))\n",
    "\n",
    "def genBlurVector(kernel_length, beta=0.5, n_tests=10, metric='dnf'):\n",
    "    '''\n",
    "    This is a helper function for solving for a blur vector in terms of it's condition #\n",
    "    '''\n",
    "    kernel_list = []\n",
    "    n_elements_max = math.floor(beta * kernel_length)\n",
    "    for test in range(n_tests):\n",
    "        indicies = np.random.randint(0, kernel_length, n_elements_max)\n",
    "        kernel = np.zeros(kernel_length)\n",
    "        kernel[indicies] = 1.0\n",
    "        kernel_list.append(kernel)\n",
    "\n",
    "    if metric == 'cond':\n",
    "        # Determine kernel with best conditioon #\n",
    "        metric_best = 1e10\n",
    "        kernel_best = []\n",
    "        for kernel in kernel_list:\n",
    "            spectra = np.abs(np.fft.fft(kernel))\n",
    "            kappa = np.max(spectra) / np.min(spectra)\n",
    "            if kappa < metric_best:\n",
    "                kernel_best = kernel\n",
    "                metric_best = kappa\n",
    "    else:\n",
    "        # Determine kernel with best dnf #\n",
    "        metric_best = 1e10\n",
    "        kernel_best = []\n",
    "        for kernel in kernel_list:\n",
    "            dnf = calcDnfFromKernel(kernel)\n",
    "            if dnf < metric_best:\n",
    "                kernel_best = kernel\n",
    "                metric_best = dnf\n",
    "\n",
    "    return (metric_best, kernel_best)\n",
    "\n",
    "\n",
    "def getOptimalDnf(kernel_size, beta=0.5, n_tests=100, metric='dnf'):\n",
    "    _, x = genBlurVector(kernel_size, beta=beta, n_tests=n_tests, metric=metric)\n",
    "    dnf = calcDnfFromKernel(x)\n",
    "    return(dnf)\n",
    "\n",
    "def dnf2snr(dnf, exposure_units, exposure_counts_per_unit=6553, dark_current_e=0.9, pattern_noise_e=3.9, readout_noise_e=2.5, camera_bits=16, full_well_capacity=30000):\n",
    "    \"\"\"\n",
    "    Function which converts deconvolution noise factor to signal to noise ratio.\n",
    "    Uses equations from https://www.photometrics.com/resources/learningzone/signaltonoiseratio.php and the dnf from the Agrawal and Raskar 2009 CVPR paper found here: http://ieeexplore.ieee.org/document/5206546/\n",
    "    Default values are for the PCO.edge 5.5 sCMOS camera (https://www.pco.de/fileadmin/user_upload/pco-product_sheets/pco.edge_55_data_sheet.pdf)\n",
    "\n",
    "    Args:\n",
    "        dnf: Deconvolution noise factor as specified in Agrawal et. al.\n",
    "        exposure_units: exposure time, time units (normally ms)\n",
    "        exposure_counts_per_unit: Average number of raw image counts for a 1 unit of exposure_units exposure time\n",
    "        dark_current_e: Dark current from datasheet, units electrons\n",
    "        pattern_noise_e: Pattern noise from datasheet, units electrons\n",
    "        readout_noise_e: Readout noise from datasheet, units electrons\n",
    "        camera_bits: Number of bits in camera\n",
    "\n",
    "    Returns:\n",
    "        A 2D numpy array which indicates the support of the optical system in the frequency domain.\n",
    "    \"\"\"\n",
    "    counts_to_e = full_well_capacity / (2 ** camera_bits - 1)\n",
    "    return counts_to_e * exposure_units * exposure_counts_per_unit \\\n",
    "        / (dnf * math.sqrt((counts_to_e * exposure_counts_per_unit + readout_noise_e) * exposure_units + (dark_current_e + pattern_noise_e)))\n",
    "\n",
    "\n",
    "def frameRateToExposure(camera_frame_rate, acquisition_strategy, \n",
    "                        motion_velocity=None, motion_velocity_max=40, motion_acceleration_max=1e3, motion_settle_time=0.25, motion_axis=1,\n",
    "                        camera_bits=16, camera_exposure_counts_per_unit=150000, camera_readout_time=0.034, \n",
    "                        illumination_gamma=0.5, max_kernel_length_mm=10, illumination_min_pulse_time=4e-6, illumination_gamma_solver=0.6,\n",
    "                        system_fov=(1,1), system_pixel_size=6.5e-3 / 10, debug=False, use_full_length=True):\n",
    "    \"\"\"\n",
    "    This function fixes frame rate (frame time) and calculates exposure counts and DNFs using the following parameters:\n",
    "    \n",
    "    GENERAL\n",
    "    - acquisition_strategy ['strobe', 'stop_and_stare' or 'coded']\n",
    "    \n",
    "    MOTION STAGE\n",
    "    - motion_velocity [mm / s] (set to None to calculate optimally - lowest velocity to match camera_frame_rate)\n",
    "    - motion_velocity_max [mm / s] (fixed)\n",
    "    - motion_acceleration_max [mm / s / s] (fixed)\n",
    "    - motion_settle_time [s] (fixed)\n",
    "    - motion_axis [int] (fixed)\n",
    "    \n",
    "    CAMERA\n",
    "    - camera_frame_rate [Hz] (fixed)\n",
    "    - camera_bits [a.u.] (fixed)\n",
    "    - camera_exposure_counts_per_unit [counts] (fixed)\n",
    "    - camera_readout_time [s] (fixed)\n",
    "    \n",
    "    ILLUMINATION\n",
    "    - illumination_gamma [in [0, 1]] (fixed)\n",
    "    - illumination_min_pulse_time [s] (fixed)\n",
    "    \n",
    "    OPTICAL SYSTEM\n",
    "    - system_fov [tuple] (fixed)\n",
    "    - system_pixel_size [float] (fixed)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Calculate frame time\n",
    "    t_frame = 1 / camera_frame_rate\n",
    "    \n",
    "    # Calculate camera exposure time\n",
    "    t_exp_max = t_frame - camera_readout_time\n",
    "    \n",
    "    # Determine maximum number of exposure units which would saturate the camera\n",
    "    signal_exposure_saturate = (2 ** camera_bits - 1) / camera_exposure_counts_per_unit\n",
    "    \n",
    "    # Calculate velocity of not provided\n",
    "    if motion_velocity is None:\n",
    "        motion_velocity = min(motion_velocity_max, system_fov[motion_axis] / t_frame)\n",
    "    else:\n",
    "        assert system_fov[motion_axis] / t_frame > motion_velocity, \"Motion velocity %g mm/s is too fast (max is %g mm/s)\" % (system_fov[motion_axis] / t_frame, motion_velocity)\n",
    "        \n",
    "    # Calculate required LED array update speed\n",
    "    t_pulse = system_pixel_size / motion_velocity\n",
    "    \n",
    "    # Calculate distance traveled during readout\n",
    "    d_readout = motion_velocity * camera_readout_time\n",
    "    \n",
    "    # Calculate FOV in pixels\n",
    "    fov_px = [int(_fov / system_pixel_size) for _fov in fov]\n",
    "\n",
    "    # Ensure strobe time isn't too fast for hardware\n",
    "    if t_pulse < illumination_min_pulse_time:\n",
    "        print('WARNING: pulse time too short!')\n",
    "        return (0,1)\n",
    "\n",
    "\n",
    "    if 'stop_and_stare' in acquisition_strategy:\n",
    "        # Calculate the time to start and stop\n",
    "        t_start_stop = motion_velocity_max / motion_acceleration_max\n",
    "        \n",
    "        # Calculate the distance to start and stop\n",
    "        d_start_stop = 0.5 * motion_acceleration_max * t_start_stop ** 2\n",
    "        \n",
    "        # Calculate movement time (constant velocity)\n",
    "        t_move = (fov[motion_axis] - d_start_stop) / motion_velocity_max\n",
    "        \n",
    "        # Calculate exposure time (frame time - (the maximum of readout amd movement))\n",
    "        signal_exposure_units = max(t_frame - max(t_move + t_start_stop, camera_readout_time), signal_exposure_saturate)\n",
    "        \n",
    "        # No deconvolution here\n",
    "        dnf = 1\n",
    "        \n",
    "    else:\n",
    "        # Determine pulse duration for strobe\n",
    "        t_pulse = system_pixel_size / motion_velocity\n",
    "        \n",
    "        # Ensure pulse is not too fast\n",
    "        if t_pulse < illumination_min_pulse_time:\n",
    "            return (0, 1)\n",
    "        \n",
    "        # Strobed acquisition\n",
    "        if 'strobe' in acquisition_strategy:\n",
    "            # Set exposure to strobe exposure\n",
    "            signal_exposure_units = t_pulse\n",
    "\n",
    "            # No deconvolution here\n",
    "            dnf = 1\n",
    "            \n",
    "        # Coded acquisition\n",
    "        elif 'code' in acquisition_strategy:\n",
    "            \n",
    "            # Limit kernel_length_px to support of blur\n",
    "            max_kernel_length_px = int(np.round((t_exp_max * motion_velocity) / system_pixel_size))\n",
    "\n",
    "            # Set kernel length to be maximum length which saturates camera\n",
    "            if use_full_length:\n",
    "                # Set kernel length to max\n",
    "                kernel_length_px = max_kernel_length_px\n",
    "                \n",
    "                # Determine number of pulses\n",
    "                pulse_count = int(round(illumination_gamma * signal_exposure_saturate / t_pulse))\n",
    "                \n",
    "                # Determine illumination gamma for solver\n",
    "                illumination_gamma_solver = pulse_count / kernel_length_px\n",
    "            else:\n",
    "                # Calculate kernel length based on illumination throughput\n",
    "                kernel_length_px = int(round(signal_exposure_saturate / t_pulse / illumination_gamma))\n",
    "                \n",
    "                # Filter to max length\n",
    "                kernel_length_px = min(kernel_length_px, max_kernel_length_px)\n",
    "                \n",
    "                # Use illumination gamma for solver\n",
    "                illumination_gamma_solver = illumination_gamma\n",
    "            \n",
    "            # Ensure kernel length is nonzero\n",
    "            assert kernel_length_px > 0\n",
    "            \n",
    "            # Determine exposure time\n",
    "            signal_exposure_units = kernel_length_px * t_pulse * illumination_gamma_solver\n",
    "\n",
    "            # Calculate DNF\n",
    "            dnf = getOptimalDnf(kernel_length_px, beta=illumination_gamma_solver, n_tests=10)\n",
    "\n",
    "    # Ensure exposure time is not negative\n",
    "    if signal_exposure_units <= 0:\n",
    "        signal_exposure_units = 0\n",
    "    \n",
    "    if debug:\n",
    "        print('exposure counts: %g, max: %g' % (signal_exposure_units * camera_exposure_counts_per_unit, signal_exposure_saturate * camera_exposure_counts_per_unit))\n",
    "        \n",
    "    # Assume the user will always use an exposure time which does not saturate the camera\n",
    "    signal_exposure_units = min(signal_exposure_units, signal_exposure_saturate)\n",
    "\n",
    "    return (signal_exposure_units, dnf)\n",
    "\n",
    "# Calculate camera exposure time\n",
    "camera_exposure_counts_per_unit = 40000 / 7e-3\n",
    "\n",
    "# Run some examples\n",
    "frame_rate = 25\n",
    "args = {'system_fov': fov, 'system_pixel_size': ps_eff_mm, 'camera_exposure_counts_per_unit': camera_exposure_counts_per_unit}\n",
    "\n",
    "t_strobe, dnf_strobed = frameRateToExposure(frame_rate, 'strobe', **args)\n",
    "snr_strobe = dnf2snr(dnf_strobed, t_strobe, exposure_counts_per_unit=camera_exposure_counts_per_unit)\n",
    "print(\"Strobed illumination at %d fps will have photon output %g seconds and SNR %g (dnf = %g)\" % (frame_rate, t_strobe, snr_strobe, dnf_strobed))\n",
    "\n",
    "t_sns, dnf_sns = frameRateToExposure(frame_rate, 'stop_and_stare', **args)\n",
    "snr_sns = dnf2snr(dnf_sns, t_sns, exposure_counts_per_unit=camera_exposure_counts_per_unit)\n",
    "print(\"Stop-and-stare illumination at %d fps will have photon output %g seconds and SNR %g (dnf = %g)\" % (frame_rate, t_sns, snr_sns, dnf_sns))\n",
    "\n",
    "t_coded, dnf_coded = frameRateToExposure(frame_rate, 'code', illumination_gamma=0.5, illumination_gamma_solver=0.05, **args)\n",
    "snr_coded = dnf2snr(dnf_coded, t_coded, exposure_counts_per_unit=camera_exposure_counts_per_unit)\n",
    "print(\"0.50 Coded illumination at %d fps will have photon output %g seconds and SNR %g (dnf = %g)\" % (frame_rate, t_coded, snr_coded, dnf_coded))\n",
    "\n",
    "t_coded, dnf_coded = frameRateToExposure(frame_rate, 'code', illumination_gamma=0.1, **args)\n",
    "snr_coded = dnf2snr(dnf_coded, t_coded, exposure_counts_per_unit=camera_exposure_counts_per_unit)\n",
    "print(\"0.10 Coded illumination at %d fps will have photon output %g seconds and SNR %g (dnf = %g)\" % (frame_rate, t_coded, snr_coded, dnf_coded))\n",
    "\n",
    "t_coded, dnf_coded = frameRateToExposure(frame_rate, 'code', illumination_gamma=0.05, **args)\n",
    "snr_coded = dnf2snr(dnf_coded, t_coded, exposure_counts_per_unit=camera_exposure_counts_per_unit)\n",
    "print(\"0.05 Coded illumination at %d fps will have photon output %g seconds and SNR %g (dnf = %g)\" % (frame_rate, t_coded, snr_coded, dnf_coded))\n",
    "\n",
    "t_coded, dnf_coded = frameRateToExposure(frame_rate, 'code', illumination_gamma=0.01, **args)\n",
    "snr_coded = dnf2snr(dnf_coded, t_coded, exposure_counts_per_unit=camera_exposure_counts_per_unit)\n",
    "print(\"0.01 Coded illumination at %d fps will have photon output %g seconds and SNR %g (dnf = %g)\" % (frame_rate, t_coded, snr_coded, dnf_coded))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot SNR vs Frame Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-13T18:56:23.301026Z",
     "start_time": "2018-12-13T18:43:16.844336Z"
    }
   },
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-213-eafdabd0063c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;31m# Coded 5%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0mt_coded_5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdnf_coded_5\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mframeRateToExposure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'code'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0millumination_gamma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.05\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m     \u001b[0msnr_coded_list_5\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdnf2snr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdnf_coded_5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt_coded_5\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexposure_counts_per_unit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcamera_exposure_counts_per_unit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-212-4f72492c5118>\u001b[0m in \u001b[0;36mframeRateToExposure\u001b[0;34m(camera_frame_rate, acquisition_strategy, motion_velocity, motion_velocity_max, motion_acceleration_max, motion_settle_time, motion_axis, camera_bits, camera_exposure_counts_per_unit, camera_readout_time, illumination_gamma, max_kernel_length_mm, illumination_min_pulse_time, illumination_gamma_solver, system_fov, system_pixel_size, debug, use_full_length)\u001b[0m\n\u001b[1;32m    193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m             \u001b[0;31m# Ensure kernel length is nonzero\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 195\u001b[0;31m             \u001b[0;32massert\u001b[0m \u001b[0mkernel_length_px\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m             \u001b[0;31m# Determine exposure time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "frame_rates = np.arange(1,80,0.1)\n",
    "snr_strobe_list = []\n",
    "snr_sns_list = []\n",
    "snr_coded_list_5 = []\n",
    "snr_coded_list_50 = []\n",
    "snr_coded_list_95 = []\n",
    "\n",
    "camera_exposure_counts_per_unit = 200\n",
    "args = {'system_fov': fov, 'system_pixel_size': ps_eff_mm, 'camera_exposure_counts_per_unit': camera_exposure_counts_per_unit}\n",
    "\n",
    "for index, rate in enumerate(frame_rates):\n",
    "    \n",
    "    # Strobed illumination\n",
    "    t_strobe, dnf_strobe = frameRateToExposure(rate, 'strobe', **args)\n",
    "    snr_strobe_list.append(dnf2snr(dnf_strobe, t_strobe*1000, exposure_counts_per_unit=camera_exposure_counts_per_unit))\n",
    "\n",
    "    # Stop and stare\n",
    "    t_sns, dnf_sns = frameRateToExposure(rate, 'stop_and_stare', **args)\n",
    "    snr_sns_list.append(dnf2snr(dnf_sns, t_sns*1000, exposure_counts_per_unit=camera_exposure_counts_per_unit))\n",
    "    \n",
    "    # Coded 5%\n",
    "    t_coded_5, dnf_coded_5 = frameRateToExposure(rate, 'code', illumination_gamma=0.05, **args)\n",
    "    snr_coded_list_5.append(dnf2snr(dnf_coded_5, t_coded_5 * 1000, exposure_counts_per_unit=camera_exposure_counts_per_unit))\n",
    "    \n",
    "    # Coded 50%\n",
    "    t_coded_50, dnf_coded_50 = frameRateToExposure(rate, 'code', illumination_gamma=0.5, **args)\n",
    "    snr_coded_list_50.append(dnf2snr(dnf_coded_50, t_coded_50 * 1000, exposure_counts_per_unit=camera_exposure_counts_per_unit))\n",
    "    \n",
    "    # Coded 95%\n",
    "    t_coded_95, dnf_coded_95 = frameRateToExposure(rate, 'code', illumination_gamma=0.95, **args)\n",
    "    snr_coded_list_95.append(dnf2snr(dnf_coded_95, t_coded_95 * 1000, exposure_counts_per_unit=camera_exposure_counts_per_unit))\n",
    "\n",
    "\n",
    "# plt.style.use('classic')\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.semilogy(frame_rates, snr_coded_list_5, 'b-', label='Coded, 5% Illuminated')\n",
    "plt.semilogy(frame_rates, snr_coded_list_50, 'g-', label='Coded, 50% Illuminated')\n",
    "plt.semilogy(frame_rates, snr_coded_list_95, 'y', label='Coded, 95% Illuminated')\n",
    "plt.semilogy(frame_rates, snr_sns_list, 'r-', linewidth=2, label='Stop and Stare')\n",
    "plt.semilogy(frame_rates, snr_strobe_list, 'w-', linewidth=2, label='Strobed')\n",
    "\n",
    "plt.ylim((0.1, 5000))\n",
    "plt.xlim((0,25))\n",
    "\n",
    "plt.legend(fontsize=24)\n",
    "plt.xlabel('Frame Rate (Hz)', fontsize=28)\n",
    "plt.ylabel('SNR', fontsize=28)\n",
    "ax = plt.gca()\n",
    "\n",
    "for tick in ax.xaxis.get_major_ticks():\n",
    "    tick.label.set_fontsize(24) \n",
    "for tick in ax.yaxis.get_major_ticks():\n",
    "    tick.label.set_fontsize(24)\n",
    "    \n",
    "plt.grid('on', which='both')\n",
    "plt.tight_layout()\n",
    "# plt.savefig(figure_directory + 'strobe_sns_coded.png', transparent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-12T19:06:34.820631Z",
     "start_time": "2018-12-12T19:06:34.792957Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "15.567978334879609\n"
     ]
    }
   ],
   "source": [
    "def calcDnfFromKernel(x):\n",
    "    x = x / np.max(x)\n",
    "    psd = np.abs(np.fft.fft(x)) ** 2\n",
    "    psd /= np.max(psd)\n",
    "    return np.sqrt(1 / len(x) * np.sum(1 / psd))\n",
    "\n",
    "N = 100\n",
    "gamma = 0.5\n",
    "x_strobe = np.zeros(N)\n",
    "x_strobe[N // 2] = 1\n",
    "\n",
    "x_coded = np.zeros(N)\n",
    "x_coded_indicies = np.random.randint(0, N, int(np.round(N * gamma)))\n",
    "for ind in x_coded_indicies:\n",
    "    x_coded[ind] = 1\n",
    "    \n",
    "print(calcDnfFromKernel(x_strobe))\n",
    "print(calcDnfFromKernel(x_coded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 100\n",
    "x = np.random.rand(N)\n",
    "F = sp.linalg.dft(N)\n",
    "FH = np.conj(F.T)\n",
    "e_ft = np.abs(np.fft.fft(x)) ** 2 * N\n",
    "AHA = FH.dot(np.diag(e_ft).dot(F))\n",
    "\n",
    "e, _ = np.linalg.eig(AHA)\n",
    "\n",
    "print(np.sum(np.abs(e) ** 2))\n",
    "print(np.sum(np.abs(e_ft * N) ** 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-12T18:35:16.482899Z",
     "start_time": "2018-12-12T18:35:16.453888Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000.0\n",
      "333882.7777054441\n",
      "\n",
      "1000.0\n",
      "11.26035154788475\n",
      "\n",
      "0.001\n",
      "2.9950631382437268e-06\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x_strobe = np.zeros(N)\n",
    "x_strobe[10] = 1\n",
    "\n",
    "x_rand = np.random.rand(N)\n",
    "x_rand /= sum(x_rand)\n",
    "x_rand *= len(x_rand) * 0.5\n",
    "\n",
    "# Random should have higher PSD\n",
    "print(np.sum(np.abs(np.fft.fft(x_strobe)) ** 2))\n",
    "print(np.sum(np.abs(np.fft.fft(x_rand)) ** 2))\n",
    "print()\n",
    "# Inverse random should have lower PSD\n",
    "print(np.sum(1 / np.abs(np.fft.fft(x_strobe)) ** 2))\n",
    "print((N // 2 - 1) / np.sum(1 / np.abs(np.fft.fft(x_rand)) ** 2))\n",
    "print()\n",
    "# Inverse random should have lower PSD\n",
    "print(1 / np.sum(np.abs(np.fft.fft(x_strobe)) ** 2))\n",
    "print(1 / np.sum(np.abs(np.fft.fft(x_rand)) ** 2))\n",
    "print()\n",
    "\n",
    "# We want the random to have a lower SNR, hwich means a higher F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ f = \\sqrt{\\frac{1}{m} trace(A^T A)^{-1}} $$\n",
    "\n",
    "$$ SNR \\propto \\frac{1}{f} $$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
